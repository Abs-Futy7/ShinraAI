"""LinkedIn Pack Pipeline Orchestrator - Pipeline B."""
from __future__ import annotations

import asyncio
import json
from typing import Any, Dict

from app.crew.linkedin_crew import LinkedInPackCrew
from app.services.run_store import RunStore
from app.utils.json_guardrails import extract_json


async def run_linkedin_pipeline(run_id: str, state: dict, store: RunStore) -> dict:
    """
    Execute Pipeline B: LinkedIn Pack generation.
    
    Flow:
    1. Claims Agent - Extract and flag risky claims (runs first!)
    2. LinkedIn Post Agent - Create post avoiding risky claims
    3. Image Prompt Agent - Generate SDXL-optimized prompt
    
    Args:
        run_id: The run ID
        state: Current run state (must have completed Pipeline A)
        store: RunStore instance
    
    Returns:
        Updated state dict with linkedin_pack data
    """
    store.log(run_id, "ðŸš€ Starting LinkedIn Pack generation (Pipeline B)")
    
    inputs = state["inputs"]
    final_blog = state.get("steps", {}).get("final", {}).get("markdown", "")
    
    if not final_blog:
        error_msg = "Pipeline A must be completed before generating LinkedIn pack"
        store.log(run_id, f"âŒ Error: {error_msg}")
        return {"error": error_msg}
    
    # Extract parameters
    prd = inputs.get("prd", "")
    tone = inputs.get("tone", "professional")
    audience = inputs.get("audience", "engineers")
    model_name = inputs.get("model_name", "groq/llama-3.1-8b-instant")
    
    # User-provided parameters (can be optional with defaults)
    product_name = inputs.get("product_name", "the product")
    goal = inputs.get("linkedin_goal", "drive awareness and engagement")
    brand_tone = inputs.get("brand_tone", tone)  # Fallback to blog tone
    product_category = inputs.get("product_category", "software/technology")
    brand_colors = inputs.get("brand_colors", "")  # Optional
    
    # â”€â”€ Build crew instance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    crew_instance = LinkedInPackCrew(model_override=model_name)
    store.log(run_id, f"Crew built (LinkedInPackCrew with Groq/llama-3.1-8b-instant)")
    
    # Get the crew object (do this ONCE before kickoff)
    crew_obj = crew_instance.crew()
    
    # Format risky claims placeholder (will be updated after claims check)
    risky_claims_text = "No risky claims identified yet"
    
    # â”€â”€ Prepare all inputs for the crew â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    all_inputs = {
        "blog_content": final_blog,
        "product_name": product_name,
        "audience": audience,
        "tone": brand_tone,
        "goal": goal,
        "risky_claims": risky_claims_text,
        "brand_tone": brand_tone,
        "product_category": product_category,
        "brand_colors": brand_colors or "not specified",
        "linkedin_post": "Will be generated by previous task"  # Placeholder
    }
    
    # â”€â”€ Execute the full crew (all 3 tasks in sequence) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    store.log(run_id, "â–¶ Running LinkedIn Pack crew (3 agents, sequential)")
    store.log(run_id, "   â†’ Step 1: Claims Agent")
    store.log(run_id, "   â†’ Step 2: LinkedIn Post Agent")
    store.log(run_id, "   â†’ Step 3: Image Prompt Agent")
    
    try:
        result = await asyncio.to_thread(
            lambda: crew_obj.kickoff(inputs=all_inputs)
        )
        
        # The result will be the final task output (image prompt)
        # We need to access individual task outputs from the crew
        store.log(run_id, "âœ“ Crew execution complete, extracting results...")
        
    except Exception as e:
        error_msg = f"Crew execution failed: {str(e)}"
        store.log(run_id, f"âŒ {error_msg}")
        return {"error": error_msg}
    
    # â”€â”€ Extract results from individual tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Access task outputs from the SAME crew object that was executed
    tasks_list = crew_obj.tasks
    
    store.log(run_id, f"Number of tasks: {len(tasks_list)}")
    
    # Parse claims check output (task 0)
    claims_dict = {}
    if len(tasks_list) > 0:
        task0_output = tasks_list[0].output
        # With output_pydantic, the parsed model is in .pydantic
        if hasattr(task0_output, 'pydantic') and task0_output.pydantic:
            claims_pydantic = task0_output.pydantic
            claims_dict = {
                "safe_claims": claims_pydantic.safe_claims,
                "risky_claims": [
                    {
                        "claim": rc.claim,
                        "risk_type": rc.risk_type,
                        "suggestion": rc.suggestion
                    } for rc in claims_pydantic.risky_claims
                ],
                "overall_assessment": claims_pydantic.overall_assessment
            }
        else:
            # Fallback to JSON extraction
            claims_raw = str(task0_output.raw) if hasattr(task0_output, 'raw') else str(task0_output)
            store.log(run_id, f"Claims raw output: {claims_raw[:200]}...")
            claims_dict = extract_json(claims_raw)
    
    if not claims_dict or "safe_claims" not in claims_dict:
        claims_dict = {
            "safe_claims": [],
            "risky_claims": [],
            "overall_assessment": "UNKNOWN"
        }
        store.log(run_id, "âš  Claims check output parsing failed")
    
    safe_claims = claims_dict.get("safe_claims", [])
    risky_claims = claims_dict.get("risky_claims", [])
    assessment = claims_dict.get("overall_assessment", "UNKNOWN")
    
    store.log(run_id, f"âœ“ Claims check: {len(safe_claims)} safe, {len(risky_claims)} risky ({assessment})")
    
    # Store claims check results
    store.update_linkedin_pack(run_id, "claims_check", claims_dict)
    
    # Parse LinkedIn post output (task 1)
    store.log(run_id, "âœ“ Parsing LinkedIn post output...")
    
    linkedin_dict = {}
    
    if len(tasks_list) > 1:
        task1_output = tasks_list[1].output
        # With output_pydantic, the parsed model is in .pydantic
        if hasattr(task1_output, 'pydantic') and task1_output.pydantic:
            linkedin_pydantic = task1_output.pydantic
            linkedin_dict = {
                "post_text": linkedin_pydantic.post_text,
                "hashtags": linkedin_pydantic.hashtags,
                "cta": linkedin_pydantic.cta,
                "word_count": linkedin_pydantic.word_count
            }
            store.log(run_id, f"âœ“ LinkedIn post parsed from pydantic ({linkedin_pydantic.word_count} words)")
        else:
            # Fallback to JSON extraction
            store.log(run_id, "âš  No pydantic output, trying JSON extraction...")
            if hasattr(task1_output, 'raw'):
                linkedin_raw = str(task1_output.raw)
                store.log(run_id, f"LinkedIn raw output (first 200 chars): {linkedin_raw[:200]}...")
                linkedin_dict = extract_json(linkedin_raw)
            elif hasattr(task1_output, 'json_dict'):
                linkedin_dict = task1_output.json_dict
            else:
                linkedin_raw = str(task1_output)
                linkedin_dict = extract_json(linkedin_raw)
    
    if not linkedin_dict or "post_text" not in linkedin_dict:
        store.log(run_id, f"âš  LinkedIn post parsing failed - dict is None or missing post_text key")
        linkedin_dict = {
            "post_text": "LinkedIn post generation failed. Please try again.",
            "hashtags": [],
            "cta": "",
            "word_count": 0
        }
    else:
        store.log(run_id, f"âœ“ LinkedIn post parsed successfully with {len(linkedin_dict.get('post_text', ''))} chars")
    
    post_text = linkedin_dict.get("post_text", "")
    hashtags = linkedin_dict.get("hashtags", [])
    word_count = linkedin_dict.get("word_count", len(post_text.split()))
    
    store.log(run_id, f"âœ“ LinkedIn post created ({word_count} words, {len(hashtags)} hashtags)")
    store.update_linkedin_pack(run_id, "linkedin_post", linkedin_dict)
    
    # Parse image prompt output (task 2)
    store.log(run_id, "âœ“ Parsing image prompt output...")
    
    image_prompt_dict = {}
    
    if len(tasks_list) > 2:
        task2_output = tasks_list[2].output
        # With output_pydantic, the parsed model is in .pydantic
        if hasattr(task2_output, 'pydantic') and task2_output.pydantic:
            image_pydantic = task2_output.pydantic
            image_prompt_dict = {
                "prompt": image_pydantic.prompt,
                "negative_prompt": image_pydantic.negative_prompt,
                "model_suggestion": image_pydantic.model_suggestion,
                "style_notes": image_pydantic.style_notes
            }
        else:
            # Fallback to JSON extraction
            image_prompt_raw = str(task2_output.raw) if hasattr(task2_output, 'raw') else str(task2_output)
            store.log(run_id, f"Image prompt raw output: {image_prompt_raw[:200]}...")
            image_prompt_dict = extract_json(image_prompt_raw)
    
    if not image_prompt_dict or "prompt" not in image_prompt_dict:
        image_prompt_dict = {
            "prompt": "Professional marketing image for technology product",
            "negative_prompt": "no text, no watermarks, no logos",
            "model_suggestion": "SDXL-Lightning",
            "style_notes": "Clean, modern aesthetic"
        }
        store.log(run_id, "âš  Image prompt parsing failed, using default")
    
    prompt = image_prompt_dict.get("prompt", "")
    model = image_prompt_dict.get("model_suggestion", "SDXL-Lightning")
    
    store.log(run_id, f"âœ“ Image prompt generated for {model}")
    
    # Store image prompt results
    store.update_linkedin_pack(run_id, "image_prompt", image_prompt_dict)
    
    # â”€â”€ Finalize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    store.log(run_id, "âœ… LinkedIn Pack generation complete!")
    store.log(run_id, f"   â†’ Claims: {assessment}")
    store.log(run_id, f"   â†’ Post: {word_count} words")
    store.log(run_id, f"   â†’ Image prompt ready for {model}")
    
    # Return complete linkedin_pack data
    linkedin_pack = {
        "claims_check": claims_dict,
        "linkedin_post": linkedin_dict,
        "image_prompt": image_prompt_dict,
        "status": "COMPLETE",
        "assessment": assessment
    }
    
    return linkedin_pack

